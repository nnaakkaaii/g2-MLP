python3 gnn/train.py \
	--name cora_debug_0914 \
	--gpu_ids 0 \
	--verbose \
	--model_name graph_attention_model \
	--dataset_name cora \
	--dataloader_name simple \
	--logger_name mlflow \
	--max_dataset_size 100000000 \
	--batch_size 32 \
	--in_dim 1433 \
	--out_dim 7 \
	--save_dir ./checkpoints \
	--train_transform_name no \
	--val_transform_name no \
	--train_ratio 0.6 \
	--n_epochs 50 \
	--n_epochs_decay 50 \
	--epoch 1 \
	--loss_name nll \
	--optimizer_name adam \
	--scheduler_name linear \
	--init_weight_name xavier \
	--module_name graph_attention \
	--attention_module_name gat_product_3d \
	--attention_hidden_dim 8 \
	--n_heads 8 \
	--gat_dropout_rate 0.1 \
	--attention_dropout_rate 0.1 \
	--leakyrelu_alpha 0.2 \
	--cora_dir ./inputs/cora \
	--num_threads 0 \
	--save_freq 5 \
	--mlflow_root_dir mlruns \
	--run_name tset \
	--lr 0.0001 \
	--beta1 0.9 \
	--beta2 0.99 \
	--init_gain 1.414